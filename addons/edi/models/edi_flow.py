# -*- encoding: utf-8 -*-

from odoo import api, fields, models, _
from odoo.exceptions import UserError

from psycopg2 import OperationalError
import logging

_logger = logging.getLogger(__name__)

DEFAULT_BLOCKING_LEVEL = 'error'


class EdiFlow(models.Model):
    """ Represent the flow of a document linked to an edi.
    It works like a state machine, with stages linked to each other.
    A document (e.g. account.move) can have multiple flows. One for each EDI used by the journal, and possibly multiples
    for a single EDI (as the flows to send and cancel are separated).
    """
    _name = 'edi.flow'
    _description = 'A single edi flow, either for sending or cancelling a document'
    _order = 'id desc'

    flow_type = fields.Selection([('send', 'Sending'), ('cancel', 'Canceling')], required=True)
    edi_format_id = fields.Many2one(
        comodel_name='edi.format',
        help='The EDI format being used by this flow.',
        required=True)
    # todo maybe add a constraint on the stage, to ensure we don't set a stage that is not allowed for the format.
    stage = fields.Char(help='The current stage of the flow. The available stages are defined by the EDI format.')
    edi_format_name = fields.Char(related='edi_format_id.name')  # todo unused as of now, remove if not needed
    res_model = fields.Char(
        string="Related Document Model",
        index=True,
        required=True)
    res_id = fields.Many2oneReference(
        string="Related Document ID",
        model_field='res_model',
        index=True,
        required=True)

    # todo remove this, replace by a boolean "done" :
    # todo to send = flow_type = 'send' and state = 'done' and not done, etc....
    # todo that or add the new boolean and make this computed if needed to simplify conditions
    state = fields.Selection([('to_send', 'To Send'), ('sent', 'Sent'), ('to_cancel', 'To Cancel'), ('cancelled', 'Cancelled')])

    edi_file_ids = fields.One2many(
        comodel_name='edi.file',
        inverse_name='edi_flow_id',
        help='The files generated by the flow.')
    additional_attachment_ids = fields.Many2many(
        comodel_name='ir.attachment',
        help='Attachments that are not part of the EDI document, but that are attached to the flow.'
             'Could be attachments shared by a batch, like the void zip file in l10n_pe')
    error = fields.Html(help='The details of the last error that happened during this flow.')

    blocking_level = fields.Selection(
        selection=[('info', 'Info'), ('warning', 'Warning'), ('error', 'Error')],
        help="Blocks the current operation of the document depending on the error severity:\n"
        "  * Info: the document is not blocked and everything is working as it should.\n"
        "  * Warning: there is an error that doesn't prevent the current flow to succeed.\n"
        "  * Error: there is an error that blocks the current flow.")
    aborted = fields.Boolean(
        help="If set to true, this flow was aborted. For example, the send flow of an EDI becomes aborted when the user"
             "cancel the process.")
    send_edi_flow_id = fields.Many2one(  # todo remove probably if only needed for peru
        comodel_name='edi.flow',
        help='The send type flow that this flow is cancelling.')

    @api.model_create_multi
    def create(self, vals_list):
        flows = super().create(vals_list)
        # Newly created flows are moving to the first stage automatically
        flows._move_to_next_stage()
        return flows

    def _get_relevants(self, edi_format='', flow_type=''):
        """ Return all relevant flows in self
        Relevant flows are flows that are related to the specified edi_format (if any) and are not aborted.
        If edi_format is set, it should only return a single value.
        :param str edi_format: The wanted edi_format
        :param str flow_type: The wanted flow_type
        :return: All relevant flows in self
        """
        return self.filtered(
            lambda f:
                not f.aborted
                and (not edi_format or f.edi_format_id == edi_format)
                and (not flow_type or f.flow_type == flow_type)
        )

    def _get_documents(self):
        """Return the documents linked to the flows in self"""
        res_model = list(set(self.mapped('res_model')))
        # To simplify the logic, this only works with a single model. It is enough for the current use cases.
        if len(res_model) != 1:
            return
        return self.env[res_model[0]].browse(self.mapped('res_id'))

    def _get_edi_format_settings(self):
        """Return the settings of the edi_format of the flows in self"""
        self.edi_format_id.ensure_one()
        assert len(self.mapped('flow_type')) == 1 and len(self.mapped('stage')) == 1, "All flows used to call _get_edi_format_settings should have the same flow_type and stage"
        # This is kind of a limitation, but when we need the settings for a particular document, there should be only one.
        # The check on exists is required, because this will be called when an ir attachment is deleted after a document has been deleted too.
        document = self._get_documents() if len(self) == 1 and self._get_documents().exists() else None
        return self.edi_format_id._get_edi_format_settings(document=document, stage=self.stage, flow_type=self.flow_type)

    def _get_stage_details(self):
        """ Return the details of the current stage of the flow.
        """
        self.edi_format_id.ensure_one()
        assert len(self.mapped('flow_type')) == 1 and len(self.mapped('stage')) == 1, "All flows used to call _get_stage_details should have the same flow_type and stage"
        return self._get_edi_format_settings()['stages'][self.flow_type].get(self.stage)

    def _do_stage(self):
        """ This should be called to execute the logic linked to the current stage of this flow.
        The time and way it is called will depend on the implementation of an edi in a module.
        :return: The result of the _do_stage method on the edi format.
        It should be a dict with the following keys:
        {
            'document.id': {
                'success': True,  # If the document was successfully processed
                'error': '',  # If the document was not successfully processed
                ...  # Any other information useful for postprocessing
            }
        }
        """
        action = self._get_stage_details().get('action')
        # If no action is defined, we just return a success for every document in self for this stage
        return action and action(self) or {document.id: {'success': True} for document in self._get_documents()}

    def _move_to_next_stage(self):
        """ Move the flow to the next stage.
        This should be called after the _do_stage method if the stage was successfully executed.
        """
        to_process = self.env['edi.flow']
        for flow in self:
            edi_format_settings = flow._get_edi_format_settings()
            flow_type_stage = edi_format_settings['stages'][flow.flow_type]
            stages = list(flow_type_stage.keys())
            if not flow.stage:
                flow.stage = stages[0]
            else:
                current_stage = stages.index(flow.stage)
                next_stage = current_stage != len(stages) - 1 and stages[current_stage + 1] or current_stage
                # The next_stage is optional, if not provided it will use the next key in the dict todo should we keep this, or should we always set the next stage?
                flow.stage = flow_type_stage.get(flow.stage).get('next_stage', next_stage)

            stage = flow_type_stage.get(flow.stage)
            flow.state = stage.get('new_state', flow.state)
            # todo this is used because for invoices, as it was before, send flows are automatically processed once in post
            # todo but cancel flows are not. TALK ABOUT THIS, this is confusing and needs to change.
            # todo check if this can replace need web service thing
            if stage.get('auto_process'):
                to_process |= flow
            # Files marked as official are linked to the document of the flow. They will appear in the chatter
            if stage.get('make_attachments_official'):
                flow._make_edi_files_official()

            message_info = stage.get('message_info')
            if message_info:
                attachment_ids = self.env['ir.attachment']
                with_attachments = message_info.get('with_attachments')
                # Sometimes we want to attach the shared attachment to the message.
                if with_attachments:
                    attachment_ids = flow.edi_file_ids.attachment_id.ids if with_attachments == 'edi_file' else flow.additional_attachment_ids.ids
                flow._get_documents().with_context(message_info.get('context', {})).message_post(
                    body=message_info.get('message'),
                    attachment_ids=attachment_ids,
                )
            to_process._process_documents_no_web_services()
            to_process._process_documents_web_services()

    def _cancel(self, with_cancellation_flow=False):
        """ Cancel the flows in self, and eventually create new cancellation flow.
        :param bool with_cancellation_flow: if set to true, a new cancellation flow will be created.
        """
        cancellation_flows_vals = []
        for flow in self:
            flow.aborted = True
            # Upon cancelling a flow, we make sure the linked attachments are no longer linked to the document.
            flow.edi_file_ids.attachment_id.write({
                'res_model': False,
                'res_id': False,
            })
            # Not all edi have a cancel flow, so we have to make sure we don't create one for nothing.
            if with_cancellation_flow and flow._get_edi_format_settings()['stages'].get('cancel'):
                cancellation_flows_vals.append({
                    'edi_format_id': flow.edi_format_id.id,
                    'flow_type': 'cancel',
                    'res_id': flow.res_id,
                    'res_model': flow.res_model,
                    'send_edi_flow_id': flow.id,
                })
        self.create(cancellation_flows_vals)

    def _prepare_jobs(self):
        """Creates a list of jobs to be performed by '_process_job' for the flows in self.
        Each flow represent a job, BUT if multiple flows have the same stage, edi_format_id,
        res_model AND the edi_format_id supports batching, they are grouped into a single job.

        :returns:         A list of tuples (documents, res_model) sorted by model
        * flows:           The flows related to this job. If edi_format_id does not support batch, length is one
        * res_model:       The model targeted by this flow. Note that it can not represent the actual res_model of the flow
        """

        # Classify jobs by (edi_format, flow_type, stage, res_model, custom_key)
        # Flow type is added as a security, so that we can safely call _do_stage on all flows of the same batch at once.
        to_process = {}
        flows = self.filtered(lambda d: d.state in ('to_send', 'to_cancel') and d.blocking_level != 'error')
        documents = flows._get_documents()
        for flow in flows:
            document = documents.filtered(lambda d: d.id == flow.res_id)[:1]
            batching_key = flow._get_edi_format_settings().get('batching_key', ())  # todo maybe batch key per stage?
            key = (flow.edi_format_id, flow.flow_type, flow.stage, document._get_document_type(), batching_key)
            to_process.setdefault(key, [])
            to_process[key].append((flow, document))

        res = []
        for key, flows in to_process.items():
            _edi_format, _flow_type, _stage, document_type, batching_key = key
            batch = self.env['edi.flow']
            for flow, document in flows:
                # Having a batching key set means we are using batching.
                if batching_key:
                    batch |= flow
                else:
                    res.append((flow, document_type))
            if batch:
                res.append((batch, document_type))
        res.sort(key=lambda d: d[1])
        return res

    @api.model
    def _process_job(self, flows, document_type):
        """Process the current stage of an edi, and eventually trigger the move to the next one.
        """
        flows.edi_format_id.ensure_one()  # All edi.flows of a job should have the same edi_format_id
        assert len(set(flow.state for flow in flows)) == 1, "All edi.flows of a job should have the same state"
        for flow in flows:
            edi_result = flow._do_stage()
            if flow.flow_type == 'send':
                self._postprocess_post_edi_results(flow, edi_result)
            elif flow.flow_type == 'cancel':
                self._postprocess_cancel_edi_results(flow, edi_result)

    @api.model
    def _postprocess_post_edi_results(self, flows, edi_result):
        """ Override this to do specific actions after the EDI stage logic has been executed for a send flow.
        The default behaviour is to call _move_to_next_stage() on the flows if the processing succeeded.
        :param flows: The flows in the batch being processed
        :param edi_result: the result returned from the edi action linked to the current stage.
        """
        for flow in flows:
            result = (edi_result or {}).get(flow.res_id, {})
            if result.get('success'):
                flow._move_to_next_stage()
            else:
                flows.write({
                    'error': result.get('error', False),
                    'blocking_level': result.get('blocking_level', DEFAULT_BLOCKING_LEVEL) if 'error' in result else False,
                })

    @api.model
    def _postprocess_cancel_edi_results(self, flows, edi_result):
        """ Override this to do specific actions after the EDI stage logic has been executed for a cancel flow.
        The default behaviour is to call _move_to_next_stage() on the flows if the processing succeeded.
        :param flows: The flows in the batch being processed
        :param edi_result: the result returned from the edi action linked to the current stage.
        """
        for flow in flows:
            result = (edi_result or {}).get(flow.res_id, {})
            if result.get('success'):
                flow._move_to_next_stage()
            else:
                flows.write({
                    'error': result.get('error', False),
                    'blocking_level': result.get('blocking_level', DEFAULT_BLOCKING_LEVEL) if 'error' in result else False,
                })

    def _process_documents_no_web_services(self):
        """ Process the job for all flows for which the format doesn't use a web service.
        """
        jobs = self.filtered(lambda f: not f.aborted and not f._get_edi_format_settings().get('needs_web_services'))._prepare_jobs()
        for documents, document_type in jobs:
            self._process_job(documents, document_type)

    def _process_documents_web_services(self, job_count=None, with_commit=True):
        ''' Process the job for all flows for which the format use a web service.

        :param job_count:   The maximum number of jobs to process if specified.
        :param with_commit: Flag indicating if a commit should be made between each job or not.
        :return:            The number of remaining jobs to process.
        '''
        all_jobs = self.filtered(lambda f: not f.aborted and f._get_edi_format_settings().get('needs_web_services'))._prepare_jobs()
        jobs_to_process = all_jobs[:job_count] if job_count else all_jobs
        for flows, document_type in jobs_to_process:
            documents_to_lock = flows.mapped('res_id')
            res_model_to_lock = flows.mapped('res_model')[0]  # Should always be len == 1 since we batch the jobs by model
            try:
                with self.env.cr.savepoint(flush=False):
                    self._cr.execute('SELECT * FROM edi_flow WHERE id IN %s FOR UPDATE NOWAIT',
                                     [tuple(flows.ids)])
                    self._cr.execute('SELECT * FROM {table} WHERE id IN %s FOR UPDATE NOWAIT'
                                     .format(table=self.env[res_model_to_lock]._table), [tuple(documents_to_lock)])
            except OperationalError as e:
                if e.pgcode == '55P03':
                    _logger.debug('Another transaction already locked documents rows. Cannot process documents.')
                    if not with_commit:
                        raise UserError(_('This document is being sent by another process already. '))
                    continue
                else:
                    raise e
            self._process_job(flows, document_type)
            if with_commit and len(jobs_to_process) > 1:
                self.env.cr.commit()

        return len(all_jobs) - len(jobs_to_process)

    @api.model
    def _cron_process_documents_web_services(self, job_count=None):
        ''' Method called by the EDI cron processing all web-services.

        :param job_count: Limit explicitely the number of web service calls. If not provided, process all.
        '''
        flows = self.search([('state', 'in', ('to_send', 'to_cancel')), ('aborted', '=', False)])
        nb_remaining_jobs = flows._process_documents_web_services(job_count=job_count)

        # Mark the CRON to be triggered again asap since there is some remaining jobs to process.
        if nb_remaining_jobs > 0:
            self.env.ref('edi.ir_cron_edi_network')._trigger()

    @api.model
    def _abandon_cancel_flow(self, documents):
        ''' Cancel the request for cancellation of the EDI.
        '''
        cancel_flows = self.env['edi.flow']
        for document in documents:
            is_document_marked = False
            for flow in document.edi_flow_ids._get_relevants(flow_type='cancel'):
                if flow._abandon_cancel_flow_conditions(document):
                    cancel_flows |= flow
                    is_document_marked = True
            if is_document_marked:  # todo probably should check if the document model has a chatter?
                document.message_post(body=_("A request for cancellation of the EDI has been called off."))

        cancel_flows._cancel()

    @api.model
    def _abandon_cancel_flow_conditions(self, document):
        """ Check if the document can be cancelled.
        To override for specific cases.
        :param document: The document to check.
        :return: True if the document can be cancelled, False otherwise.
        """
        return True

    def _create_or_update_edi_files(self, attachment_vals, is_official=False):
        """ Either create new edi files for this flow, or update the existing ones if any.
        :param attachment_vals: a list of dict with the data for each attachment process.
        """
        self.ensure_one()
        if not attachment_vals:
            return self.edi_file_ids
        if not self.edi_file_ids:
            edi_files = self._create_edi_files(attachment_vals, is_official)
        else:
            # Update the existing files or create new ones if there is no file with the code already existing.
            existing_codes = self.edi_file_ids.mapped('code')
            edi_files = self._update_edi_files([val for val in attachment_vals if val['code'] in existing_codes], is_official)
            edi_files |= self._create_edi_files([val for val in attachment_vals if val['code'] not in existing_codes], is_official)
        return edi_files

    def _create_edi_files(self, attachment_vals, is_official):
        """ Create the EDI files for the documents and link them to self.
        :param attachment_vals: a list of dict with the data for each attachment to create.
        :param is_official: True if the files are official yet, False otherwise.
        """
        self.ensure_one()
        edi_file_vals = []
        for val in attachment_vals:
            # For ease, the code is put in the vals directly.
            code = val.pop('code')
            if is_official:
                val.update({
                    'res_model': self.res_model,
                    'res_id': self.res_id,
                })
            edi_file_vals.append({
                'edi_flow_id': self.id,
                'code': code,
                'attachment_id': self.env['ir.attachment'].create(val).id,  # todo check this again
            })
        edi_files = self.env['edi.file'].create(edi_file_vals)
        return edi_files

    def _update_edi_files(self, attachment_vals, is_official):
        """ Update the EDI files for the documents and link them to self.
        :param attachment_vals: a list of dict with the data for each attachment to update.
        :param is_official: True if the files are official yet, False otherwise.
        """
        self.ensure_one()
        for val in attachment_vals:
            # don't update the official files
            edi_file = self.edi_file_ids.filtered(lambda f: f.code == val.get('code') and not f.attachment_id.res_id)
            edi_file.attachment_id.write({
                'res_model': self.res_model if is_official else False,
                'res_id': self.res_id if is_official else False,
                'type': val.get('type', edi_file.attachment_id.type),
                'name': val.get('name', edi_file.attachment_id.name),
                'datas': val.get('content', edi_file.attachment_id.datas),
                'raw': val.get('raw', edi_file.attachment_id.raw),
                'mimetype': val.get('mimetype', edi_file.attachment_id.mimetype),
            })
        return self.edi_file_ids

    def _make_edi_files_official(self):
        """ Set the res_model and res_id for all edi files in self, making them 'official'. """
        for flow in self:
            for file in flow.edi_file_ids:
                file.attachment_id.write({
                    'res_model': flow.res_model,
                    'res_id': flow.res_id,
                })

    # def action_export_xml(self):
    #     self.ensure_one()
    #     return {
    #         'type': 'ir.actions.act_url',
    #         'url':  '/web/content/account.edi.flow/%s/edi_content' % self.id
    #     }
